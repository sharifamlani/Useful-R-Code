df <- data.frame(Year,Vote,State, Turnout)
df
Results <- lm(Turnout ~ Year + Vote, data = subset(df, Year == 2020))
summary(Results)
Results <- lm(Turnout ~  Vote, data = subset(df, Year == 2020))
summary(Results)
state.abb
4*5
20 +15
#Treatment and Control Groups - At State/County Level
df$Treatment[df$State %in% df$State[1:20]] <- 0
df$Treatment[df$State %in% df$State[21:25]] <- 1
#Sharif Amlani
#R 4.0.2
#Summer 2020
######################## Code Summary ##################
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
#################### Simulate Data ##################
Year <- c(rep(2016, 50), rep(2020, 50))
State <- c(state.abb[1:50],state.abb[1:50])
Vote_2016 <- c(rep("VBM", 4*5), rep("IP", 3*5), rep("REQ", 1*5), rep("IP", 2*5)) #No you dont include these groups
Vote_2020 <- c(rep("VBM", 4*5), rep("VBM", 3*5), rep("REQ", 1*5), rep("REQ", 2*5))
table(Vote_2016,Vote_2020)
Vote <- c(Vote_2016, Vote_2020)
Turnout_2016 <- c(sample(seq(40,60,1), 4*5, replace = T), sample(seq(30,40,1), 4*5, replace = T), sample(seq(20,40,1), 2*5, replace = T))
Turnout_2020 <- c(sample(seq(40,60,1), 4*5, replace = T), sample(seq(40,60,1), 4*5, replace = T), sample(seq(30,40,1), 2*5, replace = T))
Turnout <- c(Turnout_2016, Turnout_2020)
df <- data.frame(Year,Vote,State, Turnout)
#################### Recoding ####################
df$Vote<- factor(Vote, levels = c("VBM", "APP", "IP"))
#Treatment and Control Groups - At State/County Level
df$Treatment_VBM[df$State %in% df$State[1:20]] <- 0
df$Treatment_VBM[df$State %in% df$State[21:25]] <- 1
################### Analysis ##############
Results <- lm(Turnout ~ Year + Vote, data = df)
summary(Results)
Results <- lm(Turnout ~  Vote, data = subset(df, Year == 2020))
summary(Results)
library(sjPlot)
Results <- lm(Turnout ~ as.factor(Year)*Treatment_VBM, data = subset(df, Vote %in% c("VBM", "IP")))
summary(Results)
plot_model(Results, type = "pred", terms = c("Year", "Treatment_VBM"))
Results <- lm(Turnout ~ Year + Vote, data = df)
summary(Results)
#Sharif Amlani
#R 4.0.2
#Summer 2020
######################## Code Summary ##################
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
#################### Simulate Data ##################
Year <- c(rep(2016, 50), rep(2020, 50))
State <- c(state.abb[1:50],state.abb[1:50])
Vote_2016 <- c(rep("VBM", 4*5), rep("IP", 3*5), rep("REQ", 1*5), rep("IP", 2*5)) #No you dont include these groups
Vote_2020 <- c(rep("VBM", 4*5), rep("VBM", 3*5), rep("REQ", 1*5), rep("APP", 2*5))
table(Vote_2016,Vote_2020)
Vote <- c(Vote_2016, Vote_2020)
Turnout_2016 <- c(sample(seq(40,60,1), 4*5, replace = T), sample(seq(30,40,1), 4*5, replace = T), sample(seq(20,40,1), 2*5, replace = T))
Turnout_2020 <- c(sample(seq(40,60,1), 4*5, replace = T), sample(seq(40,60,1), 4*5, replace = T), sample(seq(30,40,1), 2*5, replace = T))
Turnout <- c(Turnout_2016, Turnout_2020)
df <- data.frame(Year,Vote,State, Turnout)
#################### Recoding ####################
df$Vote<- factor(Vote, levels = c("VBM", "APP", "IP"))
#Treatment and Control Groups - At State/County Level
df$Treatment_VBM[df$State %in% df$State[1:20]] <- 0
df$Treatment_VBM[df$State %in% df$State[21:25]] <- 1
################### Analysis ##############
Results <- lm(Turnout ~ Year + Vote, data = df)
summary(Results)
Results <- lm(Turnout ~  Vote, data = subset(df, Year == 2020))
summary(Results)
library(sjPlot)
Results <- lm(Turnout ~ as.factor(Year)*Treatment_VBM, data = subset(df, Vote %in% c("VBM", "IP")))
summary(Results)
plot_model(Results, type = "pred", terms = c("Year", "Treatment_VBM"))
Results <- lm(Turnout ~ as.factor(Year)+ Treatment, data = subset(df, Vote %in% c("IP", "VBM", "APP")))
summary(Results)
plot_model(Results, type = "pred", terms = c("Year", "Treatment"))
plot_model(Results, type = "pred", terms = c("Year", "Treatment_VBM"))
Results <- lm(Turnout ~ as.factor(Year)*Treatment_VBM, data = df)
summary(Results)
df_1 <- data.frame(Vote_2016,Vote_2020,Turnout_2016, Turnout_2020)
Results <- lm(Turnout_2020 ~ Vote_2016*Vote_2020 + Turnout_2016, data = df_1)
summary(Results)
df_1
Results <- lm(Turnout ~ Year + Vote, data = df)
summary(Results)
Results <- lm(Turnout ~ as.factor(Year)*Treatment_VBM, data = df)
summary(Results)
plot_model(Results, type = "pred", terms = c("Year", "Treatment_VBM"))
tolower(BY DREW DESILVER AND A.W. GEIGER)
tolower("BY DREW DESILVER AND A.W. GEIGER")
text <- "candidate evaluations during elections, immigration policy attitudes, foreign policy attitudes, and support for democratic values and institutions"
gsub(",", ";", text)
change("candidate evaluations during elections, immigration policy attitudes, foreign policy attitudes, and support for democratic values and institutions")
change<- function(text){
return(gsub(",", ";", text))
}
change("candidate evaluations during elections, immigration policy attitudes, foreign policy attitudes, and support for democratic values and institutions")
change("American state and national politics, voting reforms, direct democracy, and social media")
change("American state and national politics, voting reforms, direct democracy, social media")
change("Aging, Applied Microeconomics, Labor Economics, Macroeconomics")
change("Life Course, Education")
change("Economics of Education, Labor Economics, Economic History")
tolower("Developmental Psychology; Social Psychology")
change("ocial norms, peer relationships, and social-emotional wellbeing")
change("social norms, peer relationships, social-emotional wellbeing")
change("policy analysis and evaluation, reform issues, charter schools, child care, early childhood development, economy and education")
change<- function(text){
return(gsub(",", ";", text))
}
change("policy analysis and evaluation, reform issues, charter schools, child care, early childhood development, economy and education")
change("Health disparities, Policy approaches to reducing cardiovascular disease, Physical activity, School health, Community-based participatory research")
tolower("Health disparities; Policy approaches to reducing cardiovascular disease; Physical activity; School health; Community-based participatory research")
tolower(change("Statistical Physics of Complex Systems and Network Science, Spatial AI, digital traces, and Environmental data"))
tolower(change("Housing, Planning, and Policy; Affordable Housing Development"))
tolower(change("early care; education services; Early Childhood Education"))
tolower(change("Economic History, Macroeconomics, Great Depression, Industrial Revolution, Property Rights and Economic Development"))
tolower(change("Economic Development, Gender Issues, Labor and Employment, Planning Theory, Poverty, Transportation"))
tolower(change("Cancer Epidemiology, Cancer Control, Cancer Survivorship, Pediatric Oncology, Biostatistics, Health Informatics, Health Services Research"))
tolower(change("HIV, Infectious Disease, and Global Medicine, Infectious Diseases"))
tolower("Michael.Reid2@ucsf.edu")
text <- "candidate evaluations during elections, immigration policy attitudes, foreign policy attitudes, and support for democratic values and institutions"
gsub(",", ";", text)
change<- function(text){
return(gsub(",", ";", text))
}
tolower(change("Climate Change, Climatology, Water, Plant Sciences, Plant Biology, Atmospheric Science, Ecology, Hydrology"))
tolower(change("Addiction; Co-morbidity, homelessness, US urban health; Chronic non-cancer pain, clinical uncertainty, scientific evidence; PTSD, bi-polar disorder, the US welfare state; Gender, reproduction"))
tolower("Kelly.Knight@ucsf.edu")
tolower(change("burn, trauma, and emergency surgery patients; molecular pathogen detection methods; Biomedical device innovation; Pharmacokinetics, pharmacodynamics, and pharmacogenetics"))
tolower(change("burn, trauma, emergency surgery patients; molecular pathogen detection methods; Biomedical device innovation; Pharmacokinetics, pharmacodynamics, and pharmacogenetics"))
tolower(change("Low-Income/Affordable Housing, Politics, Poverty, Urban Design, Urban Redevelopment"))
tolower(change("Internalizing Disorder, Suicidal Behavior, Effects of Psychological Disorder on Physical Health and Economic Outcomes, Psychiatric Epidemiology, Biological Embedding of Social Adversity"))
install.packages(c("choroplethr", "USAboundaries"))
#Rtools link
Sys.setenv(PATH = paste("C:/Rtools/bin", Sys.getenv("PATH"), sep=";"))
Sys.setenv(BINPREF = "C:/Rtools/mingw_$(64)/bin/")
install.packages("USAboundariesData")
#Rtools link
Sys.setenv(PATH = paste("C:/Rtools/bin", Sys.getenv("PATH"), sep=";"))
install.packages("USAboundariesData")
install.packages("USAboundariesData")
PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = "~/.Renviron")
Sys.which("make")
library(devtools)
find_rtools()
pkgbuild::find_rtools(debug = TRUE)
callr::rcmd_safe("config", "CC")$stdout
.libPaths()
find_rtools(debug = T)
devtools::find_rtools(debug = T)
library(devtools)
#Rtools link
Sys.setenv(PATH = paste("C:/rtools40/bin", Sys.getenv("PATH"), sep=";"))
Sys.setenv(BINPREF = "C:/rtools40/mingw_64/bin/")
install.packages("USAboundariesData")
paste("C:/rtools40/bin", Sys.getenv("PATH")
)
Sys.getenv("PATH")
116159 /.87
133516.1 - 116159
104935 /.95
110457.9 - 104935
5522.9 + 17357.1
47000/22880
470000/22880
22880/47000
1752762 / 1752762 + 519615
1752762 / (1752762 + 519615)
340375 *.75
setwd("C:/Users/Shari/OneDrive/University of California, Davis/Research Projects/Immigration One-Word Project/Data/One-Word Answers")
setwd("C:/Users/Shari/OneDrive/University of California, Davis/Research Projects/Immigration One-Word Project/Data/One-Word Answers")
setwd("C:/Users/Shari/OneDrive/University of California, Davis/Research Projects/Immigration One-Word Project/Data/Open Ended Answers")
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
#************ v1 ****************
#I run the STM package on open ended responces
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
######################## Upload Data ##################
#Set Working Directory
setwd("C:/Users/Shari/OneDrive/University of California, Davis/Research Projects/Immigration One-Word Project/Data/Open Ended Answers")
#Upload Data
Words_Pure <- read.csv("mergedQ3and4.csv", fileEncoding="UTF-8-BOM"); Words.1 <- Words_Pure
################### Examine Data ################
head(Words.1)
######################### Library #####################
library(stm)
install.packages("stm")
######################### Library #####################
library(stm)
install.packages("gutenbergr")
library(gutenbergr)
library(tidyverse)
sherlock_raw <- gutenberg_download(1661)
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
#************ v1 ****************
#I run the STM package on open ended responces
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
library(stm)
library(gutenbergr)
library(tidyverse)
######################## Upload Data ##################
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA))
sherlock
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story)
sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story)
sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES")
sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock %>% count(story)
library(tidytext)
sherlock %>%
mutate(line = row_number()) %>% #Add row numbers
unnest_tokens(word, text)
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
#************ v1 ****************
#I run the STM package on open ended responces
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
library(stm)
library(gutenbergr)
library(tidyverse)
library(tidytext)
######################## Upload Data ##################
sherlock_raw <- gutenberg_download(1661)
#################### Data Management ####################
#Add the name of the story to the data frame
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
#Count the number of lines
sherlock %>% count(story)
#Add the line numbers to the short story
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>% #Add row numbers
unnest_tokens(word, text)
tidy_sherlock
stop_words
sherlock %>%
mutate(line = row_number()) %>% #Add row numbers
unnest_tokens(word, text) %>%  #Make one word per row
anti_join(stop_words)
sherlock %>% count(story)
tidy_sherlock %>%
count(word, sort = TRUE)
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
#************ v1 ****************
#I run the STM package on open ended responces
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
library(stm)
library(gutenbergr)
library(tidyverse)
library(tidytext)
######################## Upload Data ##################
sherlock_raw <- gutenberg_download(1661)
#################### Data Management ####################
#Add the name of the story to the data frame
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
#Count the number of lines
sherlock %>% count(story)
#Add the line numbers to the short story
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>% #Add row numbers
unnest_tokens(word, text) %>%  #Make one word per row
anti_join(stop_words)
tidy_sherlock %>%
count(word, sort = TRUE)
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
#************ v1 ****************
#I run the STM package on open ended responces
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
library(stm)
library(gutenbergr)
library(tidyverse)
library(tidytext)
######################## Upload Data ##################
sherlock_raw <- gutenberg_download(1661)
#################### Data Management ####################
#Add the name of the story to the data frame
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock
#Count the number of lines
sherlock %>% count(story)
#Add the line numbers to the short story
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>% #Add row numbers
unnest_tokens(word, text) %>%  #Make one word per row
anti_join(stop_words) %>% #Remove stop word for topic modeling
filter(word != "holmes") #Remove "holmes" becasue it is unnessary and very frequent
tidy_sherlock %>%
count(word, sort = TRUE)
###################### TF - IDF ##################
library(drlib)
install.packages("drlib")
sherlock_tf_idf <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
bind_tf_idf(word, story, n) %>%
arrange(-tf_idf) %>%
group_by(story) %>%
top_n(10) %>%
ungroup
sherlock_tf_idf %>%
mutate(word = reorder_within(word, tf_idf, story)) %>%
ggplot(aes(word, tf_idf, fill = story)) +
geom_col(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ story, scales = "free", ncol = 3) +
scale_x_reordered() +
coord_flip() +
theme(strip.text=element_text(size=11)) +
labs(x = NULL, y = "tf-idf",
title = "Highest tf-idf words in Sherlock Holmes short stories",
subtitle = "Individual stories focus on different characters and narrative elements")
tidy_sherlock %>%
count(story, word, sort = TRUE)
tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
bind_tf_idf(word, story, n)
tidy_sherlock %>%
count(story, word, sort = TRUE) %>% #Count the number of words per story
bind_tf_idf(word, story, n)
library(quanteda)
tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
tidy_sherlock %>%
count(story, word, sort = TRUE)
tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
sherlock_sparse <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_sparse(story, word, n)
sherlock_sparse
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
#****************** STM Package ***********************
topic_model <- stm(sherlock_dfm,  #Data
K = 6,         #6 Topic, topic molde
verbose = FALSE,
init.type = "Spectral")
#****************** STM Package ***********************
topic_model <- stm(sherlock_dfm,  #Data
K = 6,         #6 Topic, topic molde
verbose = FALSE,
init.type = "Spectral")
topic_model
summary(topic_model)
#****************** Make into a tidy object ***********************
td_beta <- tidy(topic_model)
td_beta %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
mutate(topic = paste0("Topic ", topic),
term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = as.factor(topic))) +
geom_col(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, scales = "free_y") +
coord_flip() +
scale_x_reordered() +
labs(x = NULL, y = expression(beta),
title = "Highest word probabilities for each topic",
subtitle = "Different words are associated with different topics")
ownames(sherlock_dfm)
rownames(sherlock_dfm)
td_gamma <- tidy(topic_model, matrix = "gamma",
document_names = rownames(sherlock_dfm))
#Gamma: In this document, how much did this topic contribute to it.
ggplot(td_gamma, aes(gamma, fill = as.factor(topic))) +
geom_histogram(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~ topic, ncol = 3) +
labs(title = "Distribution of document probabilities for each topic",
subtitle = "Each topic is associated with 1-3 stories",
y = "Number of stories", x = expression(gamma))
setwd("C:/Users/Shari/OneDrive/R-Scripts/Structural Topic Modeling/Tutorial/Data")
#Sharif Amlani
#R 4.0.2
#Fall 2020
######################## Code Summary ##################
########################## Prelude #####################
rm(list=ls(all=TRUE))
options(stringsAsFactors = FALSE)
options(scipen = 3)
set.seed(1993)
######################### Functions ###################
######################### Library #####################
######################## Upload Data ##################
#Set Working Directory
setwd("C:/Users/Shari/OneDrive/R-Scripts/Structural Topic Modeling/Tutorial/Data")
#Upload Data
data <- read.csv("poliblogs2008.csv")
data
######################## Data Management ##################
processed <- textProcessor(data$documents, metadata = data)
?textProcessor
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
meta
plotRemoved(processed$documents, lower.thresh = seq(1, 200, by = 100))
out <- prepDocuments(processed$documents, processed$vocab,
+ processed$meta, lower.thresh = 15)
poliblogPrevFit <- stm(documents = out$documents, vocab = out$vocab,
K = 20,
prevalence =~ rating + s(day),
max.em.its = 75,
data = out$meta, init.type = "Spectral")
